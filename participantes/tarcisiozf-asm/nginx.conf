worker_processes 1;                 # 1 worker: minimal context switches under a sub-1 CPU limit
worker_rlimit_nofile 200000;

events {
    use epoll;
    worker_connections 65535;       # more than enough for 550 concurrent
    multi_accept on;
}

http {
    server_tokens off;
    access_log off;                 # drop access logging for latency/CPU
    # error_log /dev/stderr warn;   # uncomment if you need minimal errors
    sendfile on;
    tcp_nodelay on;                 # prioritize low latency over throughput
    tcp_nopush off;
    keepalive_timeout 15s;
    keepalive_requests 100000;
    gzip off;

    upstream backend {
        # default round-robin is lowest overhead
        server unix:/sockets/one.sock;
        server unix:/sockets/two.sock;
        keepalive 512;              # reuse upstream conns (also works over UDS)
    }

    server {
        listen 80 reuseport backlog=16384;

        location / {
            proxy_http_version 1.1;
            proxy_set_header Connection "";   # enable upstream keep-alive
            proxy_request_buffering off;      # lower latency for POST/streaming
            proxy_buffering off;              # cut a few ms; enable if you need throughput
            proxy_pass http://backend;
        }
    }
}
